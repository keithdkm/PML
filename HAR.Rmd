---
title: "A Machine Algorithm for Human Activity Recognition"
author: "Keith Miller"
date: "Monday, June 15, 2015"
output: html_document
---
## Executive Summary
This report describes and implements a machine-learning algorithm that uses data from a personal activity monitor to determine if the user of the device is performing a particular exercise in the correct way.  These devices have to date collected information about how much of a particular exercise the wearer is doing but not how well they are doing it.  The exercise in question is barbell lifts and the data was gathered from acceleromters placed on the belt, forearm, arm and dumbell of six different participants.

The participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E).

Class A corresponds to the specified execution of the exercise, while the other 4 classes correspond to common mistakes. Participants were supervised by an experienced weight lifter to make sure the execution complied to the manner they were supposed to simulate. The exercises were performed by six male participants aged between 20-28 years, with little weight lifting experience. We made sure that all participants could easily simulate the mistakes in a safe and controlled manner by using a relatively light dumbbell (1.25kg).

Read more: http://groupware.les.inf.puc-rio.br/har#ixzz3dAGZdbd3
```{r Libraries, echo = FALSE, warning=FALSE, message=FALSE}
library(caret)
library(AppliedPredictiveModeling)
library(ggplot2)
library(plyr)
library(e1071)
library(doParallel)
```


```{r Data Loading , echo= FALSE}
#Assumes that the training data is in the working directory in the pml-training.csv file
setwd("C:/Users/Keith/Google Drive/R/Practical Machine Learning/Project")
train<-read.csv("C:/Users/Keith/Google Drive/R/Practical Machine Learning/Project/pml-training.csv")
test<- read.csv("C:/Users/Keith/Google Drive/R/Practical Machine Learning/Project/pml-testing.csv")
dims<-dim(train)

```

##Exploratory Data Analysis and Pre-Processing

The dataset has a total of `r dims[1]` rows and `r dims[2]` variables.  Reviewing the data, it was determined that many of the variables have a large number of NA data and/or a large number of blank values. Further, the variables in columns 1-7 should not  be included in a prediction model as they should not be describing the behavior that we are trying to assess - they relate to the time of day, the subject performing the exercise and the group of results that is summarized by the observation. These variables will not form part of a prediction in the real world and in the case of the window variable correlate 100% with 



```{r Exploratory Data Analysis}
#identifies those variables where more than 50% of the values are NA or blank and removes them
set.seed(601)
perc.na<-function(x) sum(is.na(x))/length(x)*100
perc.blank<-function(x) sum(x=="")/length(x)*100
NAcols<-apply(train,2,perc.na)
Blankcols<-apply(train,2,perc.blank)

par(mfrow=(c(1,2)))
plot(NAcols, xlab = "Column Number", ylab = "Percentage NA values")
plot(Blankcols,xlab = "Column Number", ylab = "Percentage Blank values")
```

All columns in the upper groups in these plots will be removed from the dataset
```{r Remove columns with missng data}
badcols<-c(which(NAcols>0.9),which(Blankcols>0.9))
train<- train[,-c(1:7,badcols)]
test<- test[,-c(1:7,badcols)]  #same changes made to test set
```

Nect variables that have little or no variability and variables that are highly correlated with other variables in the set are removed.  These variables can cause problems in certain models.

```{r REmove zero variance and highly corellated variables }
#check for zero-variance predictors
zero.cols<-nearZeroVar(train)
if (length(zero.cols)>00) {train<-train[,-zero.cols];test<-test[,-zero.cols]}

#check for multi-collinearity and remove highly correlated variables
M<-cor(train[,-53])
cor.cols<-findCorrelation(M,0.9)
train<-train[,-cor.cols]
test<-test[,-cor.cols]
```

 This leaves `r dim(train)[[2]]` variables which will be the predictors used for the model

```{r Create Traingin and Validation  Sets}
# Split training datasets into train and validation sets
set.seed(601)
trainrecords<-createDataPartition(train$classe,p=0.5,list = F)
trainset<-train[trainrecords,]
validset<-train[-trainrecords,]


```

Given the size of the dataset has a large number of observations, it was decided to train models using only half the data and reserve the other half for cross validation to estimate the out-of-sample error rate

##Model Selection
The approach we will use is to use cross-validation within the caret package to determine which predictors we will use and tune the performance of the model and then use the validset data to estimate out-of-sample error rates.   We will use prediction accuracy as the measure of model effectiveness when choosing the model.  


Initially the caret package train function is run against the entire training set
```{r Model Performance, cache =TRUE}
# trellis.par.set(caretTheme())
cl <- makeCluster(detectCores())
registerDoParallel(cl)
rfallfitcv10<-train(classe~.,
                     data=trainset,
                     method = 'rf', 
                     trControl = trainControl(method='cv',
                                              number = 10 ))


#plots the importance of the top 20 variables in the model 
 

# stopCluster()

confusionMatrix(rfallfitcv10)

#plots the importance of the top 20 variables in the model 
plot(varImp(rfallfitcv10),top =10)

##This code compares the differenct models
# cvValues <- resamples(list(Linear_Model = lmTune, 
#                            Random_Forest_CV10 = rffit,
#                            Gradient_Boosting = gbmTune
# summary(cvValues)                           
                           
```

```{r Generate Answers for Submission, echo=FALSE}
#writes output files containing the answer to each question
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)

    }}
    
```




##Approach described in lectures

define error rate (type I/type II)
split data into:
training, testing, validation (optional)
pick features from the training set
use cross-validation
pick prediction function (model) on the training set
use cross-validation
if no validation set
apply 1 time to test set
if there is a validation set
apply to test set and refine
apply 1 time to validation

## References
1. Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.


Read more: http://groupware.les.inf.puc-rio.br/har#ixzz3dB0epBGD